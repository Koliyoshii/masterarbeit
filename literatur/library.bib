@article{platinsky,
   abstract = {In this paper we present the first published end-to-end production computer-vision system for powering city-scale shared augmented reality experiences on mobile devices. In doing so we propose a new formulation for an experience-based mapping framework as an effective solution to the key issues of city-scale SLAM scalability, robustness, map updates and all-time all-weather performance required by a production system. Furthermore, we propose an effective way of synchronising SLAM systems to deliver seamless real-time localisation of multiple edge devices at the same time. All this in the presence of network latency and bandwidth limitations. The resulting system is deployed and tested at scale in San Francisco where it delivers AR experiences in a mapped area of several hundred kilometers. To foster further development of this area we offer the data set to the public, constituting the largest of this kind to date.},
   author = {Lukas Platinsky and Michal Szabados and Filip Hlasek and Ross Hemsley and Luca Del Pero and Andrej Pancik and Bryan Baum and Hugo Grimmett and Peter Ondruska},
   month = {11},
   title = {Collaborative Augmented Reality on Smartphones via Life-long City-scale Maps},
   url = {http://arxiv.org/abs/2011.05370},
   year = {2020},
}
@book{doerner,
   author = {Ralf' 'DÃ¶rner and Wolfgang' 'Broll and Paul' 'Grimm and Bernhard' 'Jung},
   city = {Berlin, Heidelberg},
   doi = {10.1007/978-3-662-58861-1},
   isbn = {978-3-662-58860-4},
   publisher = {Springer Berlin Heidelberg},
   title = {Virtual und Augmented Reality (VR/AR)},
   volume = {2},
   year = {2019},
}
@book{hartleyzisserman,
   author = {Richard Hartley and Andrew Zisserman},
   doi = {10.1017/CBO9780511811685},
   isbn = {9780521540513},
   month = {3},
   publisher = {Cambridge University Press},
   title = {Multiple View Geometry in Computer Vision},
   volume = {2},
   year = {2004},
}
@inproceedings{lowe_sift,
   author = {David G. Lowe},
   doi = {10.1109/ICCV.1999.790410},
   isbn = {0-7695-0164-8},
   journal = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
   pages = {1150-1157 vol.2},
   publisher = {IEEE},
   title = {Object recognition from local scale-invariant features},
   year = {1999},
}
@article{bay_surf,
   author = {Herbert Bay and Andreas Ess and Tinne Tuytelaars and Luc Van Gool},
   doi = {https://doi.org/10.1016/j.cviu.2007.09.014},
   issn = {10773142},
   issue = {3},
   journal = {Computer Vision and Image Understanding},
   month = {6},
   pages = {346-359},
   title = {Speeded-Up Robust Features (SURF)},
   volume = {110},
   year = {2008},
}
@article{slam1,
   author = {H. Durrant-Whyte and T. Bailey},
   doi = {10.1109/MRA.2006.1638022},
   issn = {1070-9932},
   issue = {2},
   journal = {IEEE Robotics and Automation Magazine},
   month = {6},
   pages = {99-110},
   title = {Simultaneous localization and mapping: part I},
   volume = {13},
   url = {https://ieeexplore.ieee.org/document/1638022/},
   year = {2006},
}
@article{slam2,
   author = {T. Bailey and H. Durrant-Whyte},
   doi = {10.1109/MRA.2006.1678144},
   issn = {1070-9932},
   issue = {3},
   journal = {IEEE Robotics and Automation Magazine},
   month = {9},
   pages = {108-117},
   title = {Simultaneous localization and mapping (SLAM): part II},
   volume = {13},
   year = {2006},
}
@inproceedings{Sudirman,
   author = {Sud Sudirman and Abdennour El-Rhalibi},
   doi = {10.1109/CIT/IUCC/DASC/PICOM.2015.150},
   isbn = {978-1-5090-0154-5},
   journal = {2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing},
   month = {10},
   pages = {994-999},
   publisher = {IEEE},
   title = {Improving Camera Pose Estimation for Indoor Marker-less Augmented Reality},
   year = {2015},
}
@article{Santi,
   abstract = {<p>Augmented Reality (AR) is worldwide recognized as one of the leading technologies of the 21st century and one of the pillars of the new industrial revolution envisaged by the Industry 4.0 international program. Several papers describe, in detail, specific applications of Augmented Reality developed to test its potentiality in a variety of fields. However, there is a lack of sources detailing the current limits of this technology in the event of its introduction in a real working environment where everyday tasks could be carried out by operators using an AR-based approach. A literature analysis to detect AR strength and weakness has been carried out, and a set of case studies has been implemented by authors to find the limits of current AR technologies in industrial applications outside the laboratory-protected environment. The outcome of this paper is that, even though Augmented Reality is a well-consolidated computer graphic technique in research applications, several improvements both from a software and hardware point of view should be introduced before its introduction in industrial operations. The originality of this paper lies in the detection of guidelines to improve the Augmented Reality potentialities in factories and industries.</p>},
   author = {Gian Maria Santi and Alessandro Ceruti and Alfredo Liverani and Francesco Osti},
   doi = {10.3390/technologies9020033},
   issn = {2227-7080},
   issue = {2},
   journal = {Technologies},
   month = {4},
   pages = {33},
   title = {Augmented Reality in Industry 4.0 and Future Innovation Programs},
   volume = {9},
   year = {2021},
}
@article{Huang,
   abstract = {<p>Due to the popularity of indoor positioning technology, indoor navigation applications have been deployed in large buildings, such as hospitals, airports, and train stations, to guide visitors to their destinations. A commonly-used user interface, shown on smartphones, is a 2D floor map with a route to the destination. The navigation instructions, such as turn left, turn right, and go straight, pop up on the screen when users come to an intersection. However, owing to the restrictions of a 2D navigation map, users may face mental pressure and get confused while they are making a connection between the real environment and the 2D navigation map before moving forward. For this reason, we developed ARBIN, an augmented reality-based navigation system, which posts navigation instructions on the screen of real-world environments for ease of use. Thus, there is no need for users to make a connection between the navigation instructions and the real-world environment. In order to evaluate the applicability of ARBIN, a series of experiments were conducted in the outpatient area of the National Taiwan University Hospital YunLin Branch, which is nearly 1800 m2, with 35 destinations and points of interests, such as a cardiovascular clinic, x-ray examination room, pharmacy, and so on. Four different types of smartphone were adopted for evaluation. Our results show that ARBIN can achieve 3 to 5 m accuracy, and provide users with correct instructions on their way to the destinations. ARBIN proved to be a practical solution for indoor navigation, especially for large buildings.</p>},
   author = {Bo-Chen Huang and Jiun Hsu and Edward T.-H. Chu and Hui-Mei Wu},
   doi = {10.3390/s20205890},
   issn = {1424-8220},
   issue = {20},
   journal = {Sensors},
   month = {10},
   pages = {5890},
   title = {ARBIN: Augmented Reality Based Indoor Navigation System},
   volume = {20},
   year = {2020},
}
@inproceedings{liu_lai_lang,
   author = {Weiquan Liu and Baiqi Lai and Cheng Wang and Xuesheng Bian and Wentao Yang and Yan Xia and Xiuhong Lin and Shang-Hong Lai and Dongdong Weng and Jonathan Li},
   doi = {10.1109/VRW50115.2020.00178},
   isbn = {978-1-7281-6532-5},
   journal = {2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
   month = {3},
   pages = {654-655},
   publisher = {IEEE},
   title = {Learning to Match 2D Images and 3D LiDAR Point Clouds for Outdoor Augmented Reality},
   year = {2020},
}
